{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T08:19:44.862590527Z",
     "start_time": "2023-10-31T08:17:31.069552972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n",
      "Training Teacher Model\n",
      "Epoch: 20/200..  Training loss: 8748.71191..  Reg Proj: 0.00000..  Reg Latent: 0.28135..  Memory: 8745.89844..  Cost: 8748.71191.. \n",
      "Epoch: 40/200..  Training loss: 11368.81543..  Reg Proj: 0.00000..  Reg Latent: 0.75179..  Memory: 11361.29785..  Cost: 11368.81543.. \n",
      "Epoch: 60/200..  Training loss: 8175.43115..  Reg Proj: 0.00000..  Reg Latent: 0.08147..  Memory: 8174.61621..  Cost: 8175.43115.. \n",
      "Epoch: 80/200..  Training loss: 7308.98291..  Reg Proj: 0.00000..  Reg Latent: 0.08837..  Memory: 7308.09912..  Cost: 7308.98291.. \n",
      "Epoch: 100/200..  Training loss: 7540.31885..  Reg Proj: 0.00000..  Reg Latent: 0.07802..  Memory: 7539.53857..  Cost: 7540.31885.. \n",
      "Epoch: 120/200..  Training loss: 8342.84473..  Reg Proj: 0.00000..  Reg Latent: 0.11079..  Memory: 8341.73633..  Cost: 8342.84473.. \n",
      "Epoch: 140/200..  Training loss: 7948.96338..  Reg Proj: 0.00000..  Reg Latent: 0.16805..  Memory: 7947.28271..  Cost: 7948.96338.. \n",
      "Epoch: 160/200..  Training loss: 8215.87891..  Reg Proj: 0.00000..  Reg Latent: 0.20831..  Memory: 8213.79590..  Cost: 8215.87891.. \n",
      "Epoch: 180/200..  Training loss: 9172.71387..  Reg Proj: 0.00000..  Reg Latent: 2.98718..  Memory: 9142.84180..  Cost: 9172.71387.. \n",
      "Epoch: 200/200..  Training loss: 7893.89600..  Reg Proj: 0.00000..  Reg Latent: 0.05044..  Memory: 7893.39160..  Cost: 7893.89600.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/getekid/Sites/athenarc/GeoCluster/src/utils/functions.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  E = Linf_array(torch.tensor(n_points), torch.tensor(outputs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "flag is 1\n",
      "m is 10000\n",
      "i is 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/getekid/Sites/athenarc/GeoCluster/src/utils/functions.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  qp = torch.tensor(qp)\n",
      "/home/getekid/Sites/athenarc/GeoCluster/src/utils/functions.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = torch.tensor(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/getekid/Sites/athenarc/GeoCluster/src/quadtree.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  qp=torch.tensor(qp),\n",
      "/home/getekid/Sites/athenarc/GeoCluster/src/models.py:272: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  qp = torch.tensor(qp).to(device)\n",
      "/home/getekid/Sites/athenarc/GeoCluster/src/models.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  qp = torch.tensor(qp, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Student Model\n",
      "Acc:  0.3321\n",
      "Epoch:  0 Cost:  1395.1690673828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 31\u001B[0m\n\u001B[1;32m     17\u001B[0m un_args_ \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10000\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Unused param.\u001B[39;00m\n\u001B[1;32m     24\u001B[0m }\n\u001B[1;32m     26\u001B[0m student_args_ \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer_lr\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1e-3\u001B[39m,\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m30000\u001B[39m,\n\u001B[1;32m     29\u001B[0m }\n\u001B[0;32m---> 31\u001B[0m node\u001B[38;5;241m.\u001B[39mcreate_student(teacher_args_, un_args_, student_args_)\n",
      "File \u001B[0;32m~/Sites/athenarc/GeoCluster/src/quadtree.py:56\u001B[0m, in \u001B[0;36mNode.create_student\u001B[0;34m(self, teacher_args, un_args, student_args, plot)\u001B[0m\n\u001B[1;32m     54\u001B[0m student \u001B[38;5;241m=\u001B[39m Voronoi(\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)  \u001B[38;5;66;03m# initialize the voronoi network\u001B[39;00m\n\u001B[1;32m     55\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30000\u001B[39m  \u001B[38;5;66;03m# number of epochs\u001B[39;00m\n\u001B[0;32m---> 56\u001B[0m student\u001B[38;5;241m.\u001B[39mtrain_(optimizer\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(student\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mstudent_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer_lr\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     57\u001B[0m                epochs\u001B[38;5;241m=\u001B[39mstudent_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     58\u001B[0m                device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice,\n\u001B[1;32m     59\u001B[0m                qp\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor(qp),\n\u001B[1;32m     60\u001B[0m                F_ps\u001B[38;5;241m=\u001B[39mF_ps)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# TODO: Save model and plot training data.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstudent \u001B[38;5;241m=\u001B[39m student\n",
      "File \u001B[0;32m~/Sites/athenarc/GeoCluster/src/models.py:313\u001B[0m, in \u001B[0;36mVoronoi.train_\u001B[0;34m(self, optimizer, epochs, device, qp, F_ps)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cost \u001B[38;5;241m<\u001B[39m best_vor_cost:\n\u001B[1;32m    312\u001B[0m     best_vor_cost \u001B[38;5;241m=\u001B[39m cost\n\u001B[0;32m--> 313\u001B[0m     best_vor_model_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_dict()\n\u001B[1;32m    314\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2000\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;66;03m# lets check acc\u001B[39;00m\n\u001B[1;32m    316\u001B[0m     acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/GeoCluster/lib/python3.11/site-packages/torch/nn/modules/module.py:1894\u001B[0m, in \u001B[0;36mModule.state_dict\u001B[0;34m(self, destination, prefix, keep_vars, *args)\u001B[0m\n\u001B[1;32m   1892\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state_dict_pre_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m   1893\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m, prefix, keep_vars)\n\u001B[0;32m-> 1894\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_to_state_dict(destination, prefix, keep_vars)\n\u001B[1;32m   1895\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   1896\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/GeoCluster/lib/python3.11/site-packages/torch/nn/modules/module.py:1788\u001B[0m, in \u001B[0;36mModule._save_to_state_dict\u001B[0;34m(self, destination, prefix, keep_vars)\u001B[0m\n\u001B[1;32m   1785\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state_dict_pre_hooks[handle\u001B[38;5;241m.\u001B[39mid] \u001B[38;5;241m=\u001B[39m hook\n\u001B[1;32m   1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle\n\u001B[0;32m-> 1788\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_save_to_state_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, destination, prefix, keep_vars):\n\u001B[1;32m   1789\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Saves module state to `destination` dictionary, containing a state\u001B[39;00m\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;124;03m    of the module, but not its descendants. This is called on every\u001B[39;00m\n\u001B[1;32m   1791\u001B[0m \u001B[38;5;124;03m    submodule in :meth:`~torch.nn.Module.state_dict`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;124;03m            module\u001B[39;00m\n\u001B[1;32m   1800\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parameters\u001B[38;5;241m.\u001B[39mitems():\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.quadtree import Node\n",
    "from src.utils.data import loadData\n",
    "data_, _ = loadData(100)\n",
    "node = Node(data_)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "teacher_args_ = {\n",
    "    \"optimizer_lr\": learning_rate,\n",
    "    \"epochs\": 200,\n",
    "    \"times\": 10,\n",
    "    \"train_data\": torch.from_numpy(data_).float().to(),\n",
    "    \"alpha\": 5,\n",
    "    \"beta\": 10\n",
    "}\n",
    "sensitivity = 0.15\n",
    "un_args_ = {\n",
    "    \"N\": 100,\n",
    "    \"M\": 10000 - 1,\n",
    "    \"epsilon\": sensitivity,\n",
    "    \"x_area\": [0, 300],\n",
    "    \"y_area\": [0, 300],\n",
    "    \"model\": None  # Unused param.\n",
    "}\n",
    "\n",
    "student_args_ = {\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"epochs\": 30000,\n",
    "}\n",
    "\n",
    "node.create_student(teacher_args_, un_args_, student_args_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
