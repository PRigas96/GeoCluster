{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n",
      "bbox: tensor([ 1.0551e+01,  4.0005e+03, -3.1377e+00,  3.9159e+03,  6.9080e+01,\n",
      "         3.8730e+03])\n",
      "bbox: tensor([8.8590e-11, 1.0000e+00, 1.8134e-05, 9.9998e-01, 4.9036e-05, 9.9995e-01])\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src import k_tree\n",
    "from src.utils import data as dt\n",
    "import torch\n",
    "from src.k_tree import Ktree\n",
    "from src.utils.data import loadData, loadData_3d\n",
    "from src.metrics import Linf_3d\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data, _ = loadData_3d(10000, 100)\n",
    "\n",
    "if type(data) is not torch.Tensor:\n",
    "    data = torch.tensor(data).to(device)\n",
    "n = 100  # number of points\n",
    "data = data[torch.randperm(data.size(0))][:n]\n",
    "# normalize data\n",
    "x_min = data[:, 0].min().item()\n",
    "x_max = data[:, 0].max().item()\n",
    "y_min = data[:, 1].min().item()\n",
    "y_max = data[:, 1].max().item()\n",
    "z_min = data[:, 2].min().item()\n",
    "z_max = data[:, 2].max().item()\n",
    "l_max = data[:, 3].max().item()\n",
    "w_max = data[:, 4].max().item()\n",
    "h_max = data[:, 5].max().item()\n",
    "bbox = torch.tensor(\n",
    "    [\n",
    "        x_min - l_max,\n",
    "        x_max + l_max,\n",
    "        y_min - w_max,\n",
    "        y_max + w_max,\n",
    "        z_min - h_max,\n",
    "        z_max + h_max,\n",
    "    ]\n",
    ")\n",
    "print(f\"bbox: {bbox}\")\n",
    "# normalize\n",
    "data[:, 0] = (data[:, 0] - bbox[0]) / (bbox[1] - bbox[0])\n",
    "data[:, 1] = (data[:, 1] - bbox[2]) / (bbox[3] - bbox[2])\n",
    "data[:, 2] = (data[:, 2] - bbox[4]) / (bbox[5] - bbox[4])\n",
    "max_xyz = max(bbox[1] - bbox[0], bbox[3] - bbox[2], bbox[5] - bbox[4])\n",
    "data[:, 3] = data[:, 3] / max_xyz\n",
    "data[:, 4] = data[:, 4] / max_xyz\n",
    "data[:, 5] = data[:, 5] / max_xyz\n",
    "x_min = data[:, 0].min().item()\n",
    "x_max = data[:, 0].max().item()\n",
    "y_min = data[:, 1].min().item()\n",
    "y_max = data[:, 1].max().item()\n",
    "z_min = data[:, 2].min().item()\n",
    "z_max = data[:, 2].max().item()\n",
    "l_max = data[:, 3].max().item()\n",
    "w_max = data[:, 4].max().item()\n",
    "h_max = data[:, 5].max().item()\n",
    "bbox = torch.tensor(\n",
    "    [\n",
    "        x_min - l_max,\n",
    "        x_max + l_max,\n",
    "        y_min - w_max,\n",
    "        y_max + w_max,\n",
    "        z_min - h_max,\n",
    "        z_max + h_max,\n",
    "    ]\n",
    ")\n",
    "print(f\"bbox: {bbox}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to create the tree...\n",
      "====================\n",
      "\n",
      "====================\n",
      "Creating critic for node 0 that has 100 data, which is more than the threshold 98.\n",
      "Bounding box for node 0: [[8.859006410399939e-11, 1.0000000321737281], [1.8133650473523173e-05, 0.999981841201762], [4.90358017948458e-05, 0.99995097158907]]\n",
      "Creating clustering for node 0 with 3 centroids.\n",
      "====================\n",
      "Starting centroid 2\n",
      "====================\n",
      "Starting centroid 3\n",
      "Initial divergence: 31.99117660522461\n",
      "====================\n",
      "Starting iteration 1\n",
      "Centroids:  tensor([[0.0642, 0.8012, 0.7006],\n",
      "        [0.6436, 0.6934, 0.5137],\n",
      "        [0.3433, 0.6156, 0.0964]], device='cuda:0')\n",
      "Iteration 1, divergence: 0.31991177797317505\n",
      "====================\n",
      "Starting iteration 2\n",
      "Centroids:  tensor([[0.2049, 0.5984, 0.7234],\n",
      "        [0.6696, 0.6262, 0.5496],\n",
      "        [0.3948, 0.3987, 0.2669]], device='cuda:0')\n",
      "Iteration 2, divergence: 0.2769835293292999\n",
      "====================\n",
      "Starting iteration 3\n",
      "Centroids:  tensor([[0.2345, 0.5986, 0.7143],\n",
      "        [0.7049, 0.7090, 0.5082],\n",
      "        [0.4341, 0.3449, 0.2823]], device='cuda:0')\n",
      "Iteration 3, divergence: 0.2702225148677826\n",
      "====================\n",
      "Starting iteration 4\n",
      "Centroids:  tensor([[0.2345, 0.5986, 0.7143],\n",
      "        [0.6923, 0.7484, 0.4978],\n",
      "        [0.4557, 0.3350, 0.3002]], device='cuda:0')\n",
      "Iteration 4, divergence: 0.2696399986743927\n",
      "====================\n",
      "Starting iteration 5\n",
      "Centroids:  tensor([[0.2278, 0.6020, 0.7006],\n",
      "        [0.6841, 0.7526, 0.4988],\n",
      "        [0.4719, 0.3232, 0.2994]], device='cuda:0')\n",
      "Iteration 5, divergence: 0.26897329092025757\n",
      "====================\n",
      "Starting iteration 6\n",
      "Centroids:  tensor([[0.2246, 0.6017, 0.6900],\n",
      "        [0.6643, 0.7583, 0.4822],\n",
      "        [0.4904, 0.3008, 0.3052]], device='cuda:0')\n",
      "Iteration 6, divergence: 0.2675180435180664\n",
      "====================\n",
      "Starting iteration 7\n",
      "Centroids:  tensor([[0.2143, 0.5895, 0.6643],\n",
      "        [0.6605, 0.7525, 0.4746],\n",
      "        [0.5131, 0.2875, 0.3090]], device='cuda:0')\n",
      "Iteration 7, divergence: 0.26597052812576294\n",
      "====================\n",
      "Starting iteration 8\n",
      "Centroids:  tensor([[0.2108, 0.5711, 0.6450],\n",
      "        [0.6605, 0.7525, 0.4746],\n",
      "        [0.5441, 0.2802, 0.2979]], device='cuda:0')\n",
      "Iteration 8, divergence: 0.26502200961112976\n",
      "====================\n",
      "Starting iteration 9\n",
      "Centroids:  tensor([[0.2092, 0.5581, 0.6295],\n",
      "        [0.6605, 0.7525, 0.4746],\n",
      "        [0.5675, 0.2774, 0.2944]], device='cuda:0')\n",
      "Iteration 9, divergence: 0.26424816250801086\n",
      "====================\n",
      "Starting iteration 10\n",
      "Centroids:  tensor([[0.2089, 0.5521, 0.6203],\n",
      "        [0.6605, 0.7525, 0.4746],\n",
      "        [0.5799, 0.2758, 0.2952]], device='cuda:0')\n",
      "Iteration 10, divergence: 0.2638908624649048\n",
      "Final divergence: 0.2638908624649048\n",
      "====================\n",
      "getUncertaintyArea\n",
      "Centroids are [[0.20886952 0.55213773 0.6202952 ]\n",
      " [0.6604747  0.7524928  0.47455418]\n",
      " [0.57992727 0.2757658  0.29520538]]\n",
      "scale is 1.0\n",
      "dx is 1.0, dy is 0.9999637007713318, dz is 0.9999018907546997\n",
      "z is torch.Size([27000])\n",
      "Processing...\n",
      "flag is 9235\n",
      "m is 17766\n",
      "i is 27000\n",
      "Labeled 0/17766 points.\n",
      "Labeled 1000/17766 points.\n",
      "Labeled 2000/17766 points.\n",
      "Labeled 3000/17766 points.\n",
      "Labeled 4000/17766 points.\n",
      "Labeled 5000/17766 points.\n",
      "Labeled 6000/17766 points.\n",
      "Labeled 7000/17766 points.\n",
      "Labeled 8000/17766 points.\n",
      "Labeled 9000/17766 points.\n",
      "Labeled 10000/17766 points.\n",
      "Labeled 11000/17766 points.\n",
      "Labeled 12000/17766 points.\n",
      "Labeled 13000/17766 points.\n",
      "Labeled 14000/17766 points.\n",
      "Labeled 15000/17766 points.\n",
      "Labeled 16000/17766 points.\n",
      "Labeled 17000/17766 points.\n",
      "Labeled all 17766/17766 points.\n",
      "Creating critic for node 0 with 3 centroids.\n",
      "Device is: cuda:0\n",
      "====================\n",
      "Training Critic Model\n",
      "Acc:  0.358268602949454\n",
      "Epoch:  0 Cost:  109.93302917480469\n",
      "Acc:  0.9547450185748058\n",
      "Epoch:  200 Cost:  10.83484172821045\n",
      "Acc:  0.9725880896093662\n",
      "Epoch:  400 Cost:  6.915616035461426\n",
      "Acc:  0.9793988517392773\n",
      "Epoch:  600 Cost:  5.308324813842773\n",
      "Acc:  0.9860970392885287\n",
      "Epoch:  800 Cost:  4.131872653961182\n",
      "Acc:  0.9848024316109423\n",
      "Epoch:  1000 Cost:  4.129626750946045\n",
      "Acc:  0.9937521107733873\n",
      "Epoch:  1200 Cost:  1.976051926612854\n",
      "Acc:  0.990656309805246\n",
      "Epoch:  1400 Cost:  2.8977620601654053\n",
      "Acc:  0.9828886637397276\n",
      "Epoch:  1600 Cost:  4.5635881423950195\n",
      "Acc:  0.9968479117415288\n",
      "Epoch:  1800 Cost:  1.2190650701522827\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# from src.k_tree_poly import Ktree as Ktree_pls\n",
    "from src.k_tree_poly_copy import Ktree as Ktree\n",
    "from src.utils.objects.squares import loadData as loadSquares\n",
    "from src.utils import plot_tools as pt\n",
    "from src.utils import accuracy as acc\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dim = 3  # space dimension\n",
    "\n",
    "k = 3  # number of centroids to generate in the Clustering model\n",
    "clustering_args = {\n",
    "    \"epochs\": 10,  # number of epochs\n",
    "    \"pre_processing\": 10,\n",
    "    \"number_of_centroids\": k,  # number of centroids to generate in the Clustering model\n",
    "    \"dimension\": dim,  # space dimension\n",
    "    \"object_id\": \"cuboids\",  # object id\n",
    "}\n",
    "# n = 50\n",
    "n = 30\n",
    "un_args = {\n",
    "    \"N\": n,  # number of points to sample\n",
    "    \"M\": n**3 - 1,  # number of points to return\n",
    "    \"epsilon\": 0.2,  # the epsilon ball. Increase this to get more points (as var increases)\n",
    "    # .15\n",
    "}\n",
    "critic_args = {\n",
    "    \"optimizer_lr\": 5e-3,  # optimiser learning rate\n",
    "    \"epochs\": 2000,  # number of epochs\n",
    "    \"width\": 300,  # width of the model's linear layers\n",
    "    \"depth\": 5,  # depth of the model's linear layers\n",
    "}\n",
    "\n",
    "# threshold = 100 - 1\n",
    "threshold = 3 * k\n",
    "# threshold = 998\n",
    "threshold = 98\n",
    "\n",
    "# Initialise the k-tree structure.\n",
    "from src.metrics import Linf_3d\n",
    "\n",
    "# pass data to the k-tree\n",
    "distance_function = Linf_3d\n",
    "ktree = Ktree(\n",
    "    threshold,\n",
    "    data,\n",
    "    distance_function,\n",
    "    clustering_args,\n",
    "    un_args,\n",
    "    critic_args,\n",
    "    device,\n",
    "    dim,\n",
    ")\n",
    "# pass data to device\n",
    "# data = data.to(device)\n",
    "print(\"Starting to create the tree...\")\n",
    "print(\"=\" * 20)\n",
    "# ktree.create_tree(save_path_prefix=\"./models/line_segments/2d/5k/\", plot=False)\n",
    "ktree.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree node number is 4\n",
      "Tree height is 2.\n",
      "Created 3 leaves with sizes\n",
      "[39, 31, 30]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tree node number is {ktree.number_of_nodes}\")\n",
    "\n",
    "leaves = ktree.get_leaves()\n",
    "\n",
    "height = max([len(leaf.index) for leaf in leaves])\n",
    "print(f\"Tree height is {height}.\")\n",
    "\n",
    "leaf_sizes = [len(leaf.data) for leaf in leaves]\n",
    "print(f\"Created {len(leaves)} leaves with sizes\")\n",
    "print(leaf_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of queries per layer are:\n",
      "[100.]\n",
      "The percentage of correct predictions per layer is:\n",
      "[98.]\n",
      "The mean percentage of correct predictions per layer is:\n",
      "[98.]\n"
     ]
    }
   ],
   "source": [
    "acc.random_queries(ktree, 100, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoCluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
