{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  36.2173, 3145.0347,   15.4830, 3115.6570])\n",
      "tensor([-1.8616e-06,  1.0000e+00,  8.2548e-07,  1.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src import k_tree\n",
    "\n",
    "# from src.utils import data as dt\n",
    "import torch\n",
    "from src.k_tree import Ktree\n",
    "from src.utils.data import loadData, loadData_3d\n",
    "from src.metrics import Linf_simple\n",
    "\n",
    "# from src import ellipses as el\n",
    "# from . import ellipses\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = np.load(\"./data/ellipses/10000el_1_3.npy\", allow_pickle=True)\n",
    "data = np.array([data[i].ellipse.to_vector() for i in range(len(data))])\n",
    "\n",
    "# make data torch\n",
    "if type(data) is not torch.Tensor:\n",
    "    data = torch.tensor(data).to(device)\n",
    "n = 100  # get randomly 5000 data\n",
    "data = data[torch.randperm(data.size(0))[:n]]\n",
    "x_min = data[:, 2].min().item()\n",
    "x_max = data[:, 2].max().item()\n",
    "y_min = data[:, 3].min().item()\n",
    "y_max = data[:, 3].max().item()\n",
    "a_max = data[:, 0].max().item()\n",
    "b_max = data[:, 1].max().item()\n",
    "max_ab = max(a_max, b_max)\n",
    "ab_norm = max((x_max - x_min), (y_max - y_min))\n",
    "bbox = torch.tensor([x_min - max_ab, x_max + max_ab, y_min - max_ab, y_max + max_ab])\n",
    "print(bbox)\n",
    "data[:, 0] /= ab_norm\n",
    "data[:, 1] /= ab_norm\n",
    "data[:, 2] = (data[:, 2] - bbox[0]) / (bbox[1] - bbox[0])\n",
    "data[:, 3] = (data[:, 3] - bbox[2]) / (bbox[3] - bbox[2])\n",
    "x_min = data[:, 2].min().item()\n",
    "x_max = data[:, 2].max().item()\n",
    "y_min = data[:, 3].min().item()\n",
    "y_max = data[:, 3].max().item()\n",
    "a_max = data[:, 0].max().item()\n",
    "b_max = data[:, 1].max().item()\n",
    "max_ab = max(a_max, b_max)\n",
    "ab_norm = max((x_max - x_min), (y_max - y_min))\n",
    "bbox = torch.tensor([x_min - max_ab, x_max + max_ab, y_min - max_ab, y_max + max_ab])\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to create the tree...\n",
      "====================\n",
      "\n",
      "====================\n",
      "Creating critic for node 0 that has 100 data, which is more than the threshold 99.\n",
      "Bounding box for node 0: [[-1.8615601629013356e-06, 1.0000018415418612], [4.333250286628473e-06, 0.999995662712708]]\n",
      "Creating clustering for node 0 with 3 centroids.\n",
      "Initial divergence: 26.46194839477539\n",
      "====================\n",
      "Starting iteration 1\n",
      "Centroids:  tensor([[0.1029, 0.1702],\n",
      "        [0.9135, 0.3122],\n",
      "        [0.2707, 0.6595]], device='cuda:0')\n",
      "Iteration 1, divergence: 0.26461946964263916\n",
      "====================\n",
      "Starting iteration 2\n",
      "Centroids:  tensor([[0.2017, 0.1973],\n",
      "        [0.7943, 0.3572],\n",
      "        [0.3994, 0.7200]], device='cuda:0')\n",
      "Iteration 2, divergence: 0.2438584864139557\n",
      "====================\n",
      "Starting iteration 3\n",
      "Centroids:  tensor([[0.2057, 0.2309],\n",
      "        [0.7772, 0.2903],\n",
      "        [0.4597, 0.7750]], device='cuda:0')\n",
      "Iteration 3, divergence: 0.23236531019210815\n",
      "====================\n",
      "Starting iteration 4\n",
      "Centroids:  tensor([[0.1963, 0.2437],\n",
      "        [0.7574, 0.2031],\n",
      "        [0.5072, 0.7783]], device='cuda:0')\n",
      "Iteration 4, divergence: 0.22345751523971558\n",
      "====================\n",
      "Starting iteration 5\n",
      "Centroids:  tensor([[0.1856, 0.2479],\n",
      "        [0.7467, 0.1863],\n",
      "        [0.5134, 0.7743]], device='cuda:0')\n",
      "Iteration 5, divergence: 0.22232408821582794\n",
      "====================\n",
      "Starting iteration 6\n",
      "Centroids:  tensor([[0.1711, 0.2647],\n",
      "        [0.7373, 0.1874],\n",
      "        [0.5231, 0.7766]], device='cuda:0')\n",
      "Iteration 6, divergence: 0.22200064361095428\n",
      "====================\n",
      "Starting iteration 7\n",
      "Centroids:  tensor([[0.1711, 0.2647],\n",
      "        [0.7373, 0.1874],\n",
      "        [0.5231, 0.7766]], device='cuda:0')\n",
      "Iteration 7, divergence: 0.22200064361095428\n",
      "====================\n",
      "Starting iteration 8\n",
      "Centroids:  tensor([[0.1711, 0.2647],\n",
      "        [0.7373, 0.1874],\n",
      "        [0.5231, 0.7766]], device='cuda:0')\n",
      "Iteration 8, divergence: 0.22200064361095428\n",
      "====================\n",
      "Starting iteration 9\n",
      "Centroids:  tensor([[0.1711, 0.2647],\n",
      "        [0.7373, 0.1874],\n",
      "        [0.5231, 0.7766]], device='cuda:0')\n",
      "Iteration 9, divergence: 0.22200064361095428\n",
      "====================\n",
      "Starting iteration 10\n",
      "Centroids:  tensor([[0.1711, 0.2647],\n",
      "        [0.7373, 0.1874],\n",
      "        [0.5231, 0.7766]], device='cuda:0')\n",
      "Iteration 10, divergence: 0.22200064361095428\n",
      "====================\n",
      "getUncertaintyArea\n",
      "Centroids are [[0.17113143 0.26469517]\n",
      " [0.737281   0.18740565]\n",
      " [0.52314603 0.77663934]]\n",
      "scale is 1.000003695487976\n",
      "Processing...\n",
      "flag is 573\n",
      "m is 328\n",
      "i is 900\n",
      "Labeled 0/328 points.\n",
      "Labeled all 328/328 points.\n",
      "Creating critic for node 0 with 3 centroids.\n",
      "Device is: cuda:0\n",
      "====================\n",
      "Training Critic Model\n",
      "Acc:  0.4634146341463415\n",
      "Epoch:  0 Cost:  109.09416961669922\n",
      "Acc:  0.8658536585365854\n",
      "Epoch:  20 Cost:  30.99062728881836\n",
      "Acc:  0.9329268292682927\n",
      "Epoch:  40 Cost:  14.751559257507324\n",
      "Acc:  0.9725609756097561\n",
      "Epoch:  60 Cost:  9.103153228759766\n",
      "Acc:  0.9634146341463414\n",
      "Epoch:  80 Cost:  9.042646408081055\n",
      "Acc:  0.975609756097561\n",
      "Epoch:  100 Cost:  7.372443199157715\n",
      "Acc:  0.9786585365853658\n",
      "Epoch:  120 Cost:  6.051754951477051\n",
      "Acc:  0.9054878048780488\n",
      "Epoch:  140 Cost:  32.894195556640625\n",
      "Acc:  0.9664634146341463\n",
      "Epoch:  160 Cost:  8.662575721740723\n",
      "Acc:  0.9786585365853658\n",
      "Epoch:  180 Cost:  5.880988121032715\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# from src.k_tree_poly import Ktree as Ktree_pls\n",
    "from src.k_tree_poly_copy import Ktree as Ktree\n",
    "from src.utils.objects.squares import loadData as loadSquares\n",
    "from src.utils import plot_tools as pt\n",
    "from src.utils import accuracy as acc\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dim = 2  # space dimension\n",
    "\n",
    "k = 3  # number of centroids to generate in the Clustering model\n",
    "clustering_args = {\n",
    "    \"epochs\": 10,  # number of epochs\n",
    "    \"pre_processing\": 10,\n",
    "    \"number_of_centroids\": k,  # number of centroids to generate in the Clustering model\n",
    "    \"dimension\": dim,  # space dimension\n",
    "    \"object_id\": \"ellipses\",  # object id\n",
    "}\n",
    "# n = 50\n",
    "n = 30\n",
    "un_args = {\n",
    "    \"N\": n,  # number of points to sample\n",
    "    \"M\": n**2 - 1,  # number of points to return\n",
    "    \"epsilon\": 0.2,  # the epsilon ball. Increase this to get more points (as var increases)\n",
    "    # .15\n",
    "}\n",
    "critic_args = {\n",
    "    \"optimizer_lr\": 5e-3,  # optimiser learning rate\n",
    "    \"epochs\": 200,  # number of epochs\n",
    "    \"width\": 300,  # width of the model's linear layers\n",
    "    \"depth\": 5,  # depth of the model's linear layers\n",
    "}\n",
    "\n",
    "# threshold = 100 - 1\n",
    "# threshold = 3 * k\n",
    "threshold = 99\n",
    "# threshold = 998\n",
    "# threshold = 98\n",
    "\n",
    "# Initialise the k-tree structure.\n",
    "from src.metrics import distance_ellipse_2_point\n",
    "\n",
    "# pass data to the k-tree\n",
    "distance_function = distance_ellipse_2_point\n",
    "ktree = Ktree(\n",
    "    threshold,\n",
    "    data,\n",
    "    distance_function,\n",
    "    clustering_args,\n",
    "    un_args,\n",
    "    critic_args,\n",
    "    device,\n",
    "    dim,\n",
    ")\n",
    "# pass data to device\n",
    "# data = data.to(device)\n",
    "print(\"Starting to create the tree...\")\n",
    "print(\"=\" * 20)\n",
    "# ktree.create_tree(save_path_prefix=\"./models/line_segments/2d/5k/\", plot=False)\n",
    "ktree.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree height is 2.\n",
      "Created 3 leaves with sizes\n",
      "[27, 29, 44]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Report some tree stats.\n",
    "leaves = ktree.get_leaves()\n",
    "number_of_nodes = ktree.number_of_nodes\n",
    "\n",
    "height = max([len(leaf.index) for leaf in leaves])\n",
    "print(f\"Tree height is {height}.\")\n",
    "\n",
    "leaf_sizes = [len(leaf.data) for leaf in leaves]\n",
    "print(f\"Created {len(leaves)} leaves with sizes\")\n",
    "print(leaf_sizes)\n",
    "print(number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of queries per layer are:\n",
      "[100.]\n",
      "The percentage of correct predictions per layer is:\n",
      "[99.]\n",
      "The mean percentage of correct predictions per layer is:\n",
      "[99.]\n"
     ]
    }
   ],
   "source": [
    "acc.random_queries(ktree, 100, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoCluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
